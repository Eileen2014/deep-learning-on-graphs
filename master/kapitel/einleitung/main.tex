\chapter{Einleitung}
\label{einleitung}

Convolutional Neural Networks, eine Spezialform der neuronalen Netze, gelten dank ihrer effizienten Architektur und ihrer Fähigkeit, lokal stationäre Strukturen auf multiskalare, hierarchische Merkmale zu übertragen, als Allzweckmittel zu Problemen in Bereichen der Bild-, Video- und Spracherkennung~\cite{Defferrard}.
Sie sind jedoch nur im Kontext regulärer Datendomänen wohldefiniert.
So lassen sich aber insbesondere zahlreiche Probleme als maschinelles Lernen auf irregulär strukturierten Daten verstehen.
Dabei liefern Graphen eine geeignete generische Datenstruktur, die es ermöglicht, eine Vielzahl dieser Probleme wie etwa in Bereichen der sozialen Netzwerke, der Biologie, Chemie oder Telekommunikation zu modellieren~\cite{Shuman}.
Es ist daher nicht verwunderlich, dass in der Vergangenheit zahlreiche Anstrengungen unternommen wurden, den Faltungsoperator der Convolutional Neural Networks für die Anwendung auf irregulären Graphstrukturen zu generalisieren~\cite{patchy, Defferrard, gcn}.
Diese Verfahren lassen sich dabei grob in zwei unterschiedliche Herangehensweisen gliedern:
\begin{enumerate}
  \item Das \textbf{räumliche Lernen auf Graphen} widmet sich der räumlichen Verschiebung eines Filters auf den Knoten eines Graphen ähnlich zu der Verschiebung eines Filters auf einem zweidimensionalen Bild oder einem eindimensionalen Audiosignal~\cite{patchy}.
  Dafür wird zu einem Knoten eine feste sowie eindeutige Nachbarschaft definiert und ein gemeinsamer Filter auf allen Nachbarschaften einer Knotenauswahl angewendet.
  \item Das \textbf{spektrale Lernen auf Graphen} basiert auf der spektralen Graphentheorie und formuliert einen Faltungsoperator auf Graphen über die Zerlegung seiner Knotenmerkmale in das Spektrum des Graphen ähnlich zu der Transformation eines Signals in dessen Frequenzraum mittels der klassischen Fourier-Transformation.
  Eine Multiplikation der Knotenmerkmale in der spektralen Domäne entspricht damit einer Faltung in der Domäne des Graphen.
\end{enumerate}
Beide Herangehensweisen zeichnen sich dabei im Gegensatz zur klassischen Faltung der Convolutional Neural Networks auf regulären Strukturen durch ihre (notwendigerweise) rotationsinvariante Faltung aus.
In dieser Arbeit motivieren wir daher zwei Ansätze \bzgl{} einer rotationsvarianten Faltung auf Graphen, bei denen Knoten eine eindeutige Position im zweidimensionalen euklidischen Raum zugeordnet sind.

\input{kapitel/einleitung/problemstellung}
\input{kapitel/einleitung/aufbau}

\section{Versuchsaufbau}
\label{versuchsaufbau}

Generelle Netzstruktur, softmax auf Klassen abgebildet
Conv mit MaxPool gefolgt von AveragePool auf Fully Connect auf Softmax

\subsection{Datensätze}
\label{datensaetze}

Die vorgestellten Faltungsmethoden aus Kapitel~\ref{raeumliches_lernen} und~\ref{spektrales_lernen} \bzgl{} des Lernens auf zweidimensionalen euklidischen Graphen wurden über einer Reihe von Datensätzen verifiziert, die im Folgenden vorgestellt werden.
Dafür wurden die Bildermengen in eine Superpixelrepräsentation (\gls{SLIC} und Quickshift) konvertiert und darauf basierend in eine Graphrepräsentation transformiert (\vgl{} Kapitel~\ref{graphrepraesentationen_von_bildern}).
Zusätzlich zu der Präsentation der Datensätze enthält dieses Kapitel damit insbesondere die Parameterwahl der jeweiligen Superpixelalgorithmen, welche jeweils händisch über einer Untermenge der Bilder eines jeden Datensatzes ermittelt wurden, und weiterhin die entsprechenden Merkmalsselektionen, die nach dem beschriebenen Prinzip aus Kapitel~\ref{merkmalsselektion} errechnet wurden.

\paragraph{MNIST}
\label{mnist}

Der \emph{\gls{MNIST}} Datensatz enthält eine große Menge eindeutig klassifizierter handgeschriebener Zahlen von $0$ bis $9$, welcher daher zum Lernen einer Schrift- \bzw{} Zahlenerkennung genutzt werden kann~\cite{mnist}.
Er besteht aus $55000$ Trainingsbildern, $5000$ Validierungsbildern sowie $10000$ Trainingsbildern.
Die Bilder des Datensatzes sind einheitlich auf die Größe $28 \times 28$ skaliert und besitzen lediglich einen Farbkanal mit Grauwerten, welcher angibt, ob ein Pixel des Bildes zu einer Zahl (weiß), zu deren Rand oder zum Hintergrund (schwarz) gehört~\cite{mnist}.
Aufgrund seiner kleinen Datengröße und leichten Handhabung gilt er als die ideale Einführung in Prinzipien des maschinellen Lernens und zeichnet sich damit als ideal für die Verifizierung eines neuen Ansatzes \bzgl{} neuronaler Netze aus.
Insbesondere kann der Datensatz während des gesamten Trainings im Speicher gehalten werden, was den Aufwand \bzgl{} der Verarbeitung und Eingabe der Daten auf ein Minimum reduziert.

Die ermittelten Parameter \bzgl{} der beiden benutzten Superpixelalgorithmen sind in Tabelle~\ref{tab:mnist} gegeben.
Für \gls{SLIC} sind das die Parameter $K \in \gls{N}$, \dhe{} die Anzahl der gewünschten Segmente, sowie $F \in \gls{R}$ für die Gewichtung zwischen der Form und den Farbabgrenzungen der Superpixel.
Für Quickshift ergeben sich dagegen drei wählbare Parameter — $\gls{sigma} \in \gls{R}$ für die Wahl der Standardabweichung der Gaußfunktion, $\alpha \in \gls{R}$ für die Gewichtung des Farbterms sowie $S \in \gls{N}$ zur Einschränkung der Berechnung über ein Fenster der Größe $S \times S$.
Für eine detaillierte Beschreibung der Parameter sei auf Kapitel~\ref{superpixel_verfahren} verwiesen.
\begin{table}[htpb]
\centering
\begin{tabular}{rlrlrlrlrlrl}
  \toprule
  \multicolumn{6}{c}{\gls{SLIC}} & \multicolumn{6}{c}{Quickshift}\\
  \midrule
  $K$: & $100$ & $F$: & $5$ & & & $\gls{sigma}$: & $2$ & $\alpha$: & $1$ & $S$: & $2$\\
  \midrule
  $\overline{N}$: & $64.6$ & $N_{\min}$: & $50$ & $N_{\max}$: & $80$ & $\overline{N}$: & $2$ & $N_{\min}$: & $1$ & $N_{\max}$: & $2$\\
  $\overline{\gls{degree}}$: & $4.2$ & $\gls{degree}_{\min}$: & $1$ & $\gls{degree}_{\max}$: & $16$ & $\overline{\gls{degree}}$: & $2$ & $\gls{degree}_{\min}$: & $1$ & $\gls{degree}_{\max}$: & $2$\\
  \bottomrule
\end{tabular}
\caption[Parameterwahl des \gls{MNIST} Datensatzes]{Parameterwahl des \gls{MNIST} Datensatzes}
\label{tab:mnist}
\end{table}
Aus der Wahl der Parameter ergeben sich die ebenfalls in der Tabelle datierten Werte der durchschnittlichen Anzahl an Knoten $\overline{N}$ und deren minimaler \bzw{} maximaler Anzahl $N_{\min}$ \bzw{} $N_{\max}$ sowie dem durchschnittlichen, minimalen und maximalen Knotengrad $\overline{\gls{degree}}$, $\gls{degree}_{\min}$, $\gls{degree}_{\max}$ über der Menge aller aus den Bildern generierten Graphen bei einer Konnektivität von $8$.
\todo{noch ein satz hierzu}
Abbildung~\ref{fig:mnist} veranschaulicht das Resultat der beiden Superpixel- \bzw{} Graphrepräsentationen eines Bildes aus dem \gls{MNIST} Datensatz.
\input{figures/mnist}


% Bei den Datensätzen insbesondere auch die Superpixelalgorithmen erwähnen
% das heißt wie viele Superpixel
% welche Parameter
% mean/max Knotengrad


Merkmalsselektion











% Wie viele Merkmale und welche?


\paragraph{CIFAR-10}
\label{cifar_10}

\cite{cifar_10}

Der \emph{\gls{Cifar}} Datensatz
Er liegt in zwei Versionen vor, \gls{Cifar}-10 und \gls{Cifar}-100, wobei sich diese Arbeit an dem weitaus beliebteren Datensatz \gls{Cifar}-10 bedient.

\input{figures/cifar_10}

% \paragraph{Tiny ImageNet}
% \label{tiny_image_net}

% \cite{imagenet}

\paragraph{PASCAL VOC}
\label{pascal_voc}

\emph{\gls{Pascal}} Datensatz
\cite{pascal_voc}

\input{figures/pascal_voc}

\subsection{Metriken}
\label{metriken}

Loss Function
Accuracy

\subsection{Parameterwahl}
\label{parameterwahl}

Vorstellung aller Parameter
Was gibt es denn hier überhaupt?
Dropout, L2 Regularisierung?
BatchSize?
Globale/normale Lokalisierung
Standardabweichung für Gauß
LEARNING RATE, LEARNING RATE DECAY

Alle Faltungen wurden dabei mit einer Partitionsgröße von $8$ bei $K=0$ und $K=1$ implementiert, um ein \gls{CNN} mit einem $3 \times 3$ Filter zu simulieren.
Es erscheint jedoch vorstellbar die Filtergröße bei größerer lokaler Kontrollierbarkeit, \dhe{} $K > 1$, weiter zu reduzieren und die Gefahr des Overfittings damit aufgrund der kleineren Anzahl an Trainingsparametern einzuschränken.

\paragraph{Datenreduktion}
\label{datenreduktion}

\subsection{Augmentierung von Graphen}
\label{augmentierung_von_graphen}

hier auf die Formeln von TensorFlow referenzieren, d.h. TensorFlow Quelle angeben
\cite{tensorflow}

Augmentierung auf Graphen über left/right
Farbanpassungen


nesser ist es, dass Bild vorher zu ändern, da sich dadurch die Superpixelrepräsentation ändert
und folglich zu realisiterischer Augmentierung führt.

\subsection{Vorverarbeitung und Eingabe der Daten}
\label{vorverarbeitung}

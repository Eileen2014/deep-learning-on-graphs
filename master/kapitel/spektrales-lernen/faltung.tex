\section{Spektraler Faltungsoperator}
\label{spektraler_faltungsoperator}

Sei $\ve{f} \in \gls{R}^N$ ein Signal auf den Knoten eines Graphen \gls{G}, welches abhängig von der Struktur des Graphen weiter verarbeitet werden soll.
Es ist jedoch nicht selbstverständlich, wie recht einfache, dennoch fundamentale Signalverarbeitungsprozesse wie Translation oder Filterung und die daraus entstehende Faltung in der Domäne des Graphen definiert werden können~\cite{Shuman}.
So kann ein analoges Signal $f\left(t\right)$ \bspw{} mittels $f\left(t-3\right)$ um $3$ nach rechts verschoben werden.
Es ist hingegen völlig unklar, was es bedeutet, ein Graphsignal auf den Knoten um $3$ nach rechts zu bewegen (\vgl{}~\cite{Shuman}).
Die spektrale Graphentheorie bietet uns dafür einen geeigneten Weg, indem Eingabesignale in das Spektrum des Graphen zerlegt \bzw{} abgebildet, modifiziert und wieder retransformiert werden können.

\subsection{Graph-Fourier-Transformation}
\label{graph_fourier_transformation}

Das Spektrum eines Graphen \gls{G} bilden die Eigenwerte ${\left\{\gls{lambda}_n\right\}}_{n=1}^N$ der Laplace-Matrix \gls{Lboth} von \gls{G}.
Diese werden deshalb auch oft als die \emph{Frequenzen} von \gls{G} betitelt.
In der spektralen Domäne können wir ein Eingabeignal \ve{f} über \gls{G} dann analog wie ein zeitdiskretes Abtastsignal in der Fourier-Domäne behandeln.

\paragraph{Klassische Fourier-Transformation}
\label{klassische_fourier_transformation}

Die Fourier-Transformation $\hat f$ einer Funktion $f\left(t\right)$ ist definiert als~\cite{Shuman}
\begin{equation*}
  \hat f\left(\omega\right) \coloneqq \left\langle f, e^{2\pi i\omega t} \right\rangle = \int_{\gls{R}} f\left(t\right)e^{-2\pi i\omega t}\,\mathrm{d}t.
\end{equation*}
Die komplexen Exponentiale $e^{2\pi i\omega t}$ beschreiben dabei die Eigenfunktionen des eindimensionalen Laplace-Beltrami Operators~\cite{Shuman}:
\begin{equation}
  - \nabla^2 e^{2\pi i\omega t} = - \frac{\partial^2}{\partial t^2} e^{2\pi i \omega t} = {\left(2\pi \omega\right)}^2 e^{2\pi i\omega t}.
  \label{eq:laplace_eigenfunktionen}
\end{equation}
$\hat f$ kann damit als die Ausdehnung von $f$ in Bezug auf die Eigenfunktionen des Laplace-Beltrami Operators $\nabla^2$ verstanden werden~\cite{Hammond}.
\\\\
Analog lässt sich die \emph{Graph-Fourier-Transformation} einer Funktion $f \colon \gls{V} \to \gls{R}$ \bzw{} $\ve{f} \in \gls{R}^N$ auf den Knoten eines Graphen \gls{G} als Ausdehnung von $f$ in Bezug auf die Eigenvektoren ${\left\{\gls{eiv}_n\right\}}_{n=1}^N$ der Laplace-Matrix \gls{Lboth} definieren~\cite{Shuman}:
\begin{equation}
  \hat f\left(\gls{lambda}_i\right) \coloneqq \left\langle \ve{f}, \gls{eiv}_i \right\rangle
  \qquad
  \text{\bzw{}}
  \qquad
  \ve{\hat f} \coloneqq \gls{Eiv}^{\top}\ve{f}.
  \label{eq:graph_fourier_transformation}
\end{equation}
Die inverse Graph-Fourier-Transformation ergibt sich dann als~\cite{Shuman}
\begin{equation}
  f\left(\gls{v}_i\right) = \sum_{n=1}^N \hat f\left(\gls{lambda}_n\right) {\left(\gls{eiv}_n\right)}_i
  \qquad
  \text{\bzw{}}
  \qquad
  \ve{f} = \gls{Eiv}\ve{\hat f}.
  \label{eq:inverse_graph_fourier_transformation}
\end{equation}

In der klassischen Fourier-Analyse sind für die Eigenwerte ${\left\{{\left(2\pi \omega\right)}^2\right\}}_{\omega \in \gls{R}}$ in~\eqref{eq:laplace_eigenfunktionen} nahe bei Null die korrespondieren Eigenfunktionen kleine, weich schwingende Funktionen, wohingegen für größere Eigenwerte \bzw{} Frequenzen die Eigenfunktionen sehr schnell und zügig anfangen zu oszillieren.
Bei der Graph-Fourier-Transformation ist dies ähnlich.
So ist für \gls{L} der erste Eigenvektor $\gls{eiv}_1 = 1/\sqrt{N}{\left[1, \ldots, 1\right]}^{\top}$ zum Eigenwert $\gls{lambda}_1 = 0$ konstant und an jedem Knoten gleich.
Generell zeigt sich, dass die Eigenvektoren geringer Frequenzen nur geringfügig im Graph variieren, wohingegen Eigenvektoren größerer Eigenwerte immer unähnlicher werden (\vgl{}~\cite{Shuman}).
\\\\
Die Graph-Fourier-Transformation~\eqref{eq:graph_fourier_transformation} und ihre Inverse~\eqref{eq:inverse_graph_fourier_transformation} bieten uns eine Möglichkeit ein Signal in zwei unterschiedlichen Domänen zu repräsentieren, nämlich der Knotendomäne, \dhe{} das unveränderte Signal auf der Knotenmenge $f\left(\gls{v}_i\right)$, und der spektralen Domäne, \dhe{} das transformierte Signal in das Spektrum des Graphen $\hat f\left(\gls{lambda}_i\right)$.
Diese Transformation erlaubt uns die Formulierung fundamentaler Signalverarbeitungsoperationen.

\subsection{Spektrale Filterung}
\label{spektrale_filterung}

In der Signalverarbeitung versteht man unter der Frequenzfilterung die Transformation eines Eingabesignals in die Fourier-Domäne und der verstärkenden oder dämpfenden Veränderung der Amplituden der Frequenzkomponenten.
Formal betrachtet ergibt dies
\begin{equation}
  \hat f_{\mathrm{out}}\left(\omega\right) \coloneqq \hat f_{\mathrm{in}}\left(\omega\right)\hat g\left(\omega\right)
  \label{eq:fourier_filtering}
\end{equation}
mit dem Filter $\hat g \colon \gls{R} \to \gls{R}$.
\citeauthor{Shuman} zeigen, dass die Filterung in der Fourier-Domäne äquivalent zu einer Faltung in der Zeitdomäne ist, \dhe{}
\begin{equation}
  \left(f_{\mathrm{in}} \star g\right)\left(t\right) \coloneqq \int_{\gls{R}} f_{\mathrm{in}}\left(\tau\right)g\left(t - \tau\right)\, \mathrm{d}\tau = f_{\mathrm{out}}\left(t\right).
  \label{eq:fourier_faltung}
\end{equation}

Wir können die Filterung der Frequenzen in der Fourier-Domäne analog zu~\eqref{eq:fourier_filtering} für die spektrale Domäne auf Graphen über
\begin{equation*}
  \hat f_{\mathrm{out}}\left(\gls{lambda}_i\right) \coloneqq \hat f_{\mathrm{in}}\left(\gls{lambda}_i\right)\hat g\left(\lambda_i\right)
  \qquad
  \text{\bzw{}}
  \qquad
  \ve{\hat f}_{\mathrm{out}} \coloneqq \ve{\hat f}_{\mathrm{in}} \gls{hadamard} \ve{\hat g}
\end{equation*}
beschreiben, wobei \gls{hadamard} das elementweise Hadamard-Produkt ist~\cite{Shuman}.
$\ve{\hat g} \in \gls{R}^N$ ist damit ein \emph{nicht-parametrischer} Filter, \dhe{} ein Filter, dessen Werte für alle Frequenzen ${\left\{\gls{lambda}_n\right\}}_{n=1}^N$ frei wählbar sind~\cite{Defferrard}.
Daraus ergibt sich analog zu~\eqref{eq:fourier_faltung} der \emph{spektrale Faltungsoperator} auf Graphen in der Knotendomäne mit Hilfe der Graph-Fourier-Transformation~\eqref{eq:graph_fourier_transformation} und ihrer Inversen~\eqref{eq:inverse_graph_fourier_transformation} als~\cite{Shuman, Defferrard}
\begin{equation}
  \ve{f}_{\mathrm{in}} \star \ve{\hat g} \coloneqq \gls{Eiv}\left(\left(\gls{Eiv}^{\top}\ve{f}_{\mathrm{in}}\right) \gls{hadamard} \ve{\hat g}\right) = \ve{f}_{\mathrm{out}}.
  \label{eq:spektraler_faltungsoperator}
\end{equation}

\subsection{Polynomielle Approximation}
\label{polynomielle_approximation}

Es zeigt sich, dass die Benutzung des spektralen Faltungsoperators in~\eqref{eq:spektraler_faltungsoperator} im Kontext eines \glspl{CNN} auf Graphen mehrere Schwächen aufweist.
So ist \zB{} die Auswertung von $\ve{f}_{\mathrm{in}} \star \ve{\hat g}$ extrem berechnungsintensiv ist, denn die Multiplikation mit der dichtbesetzten Eigenvektormatrix \gls{Eiv} liegt in $\gls{O}\left(N^2\right)$~\cite{Defferrard}.
Zudem muss \gls{Eiv} zuerst bestimmt werden — ein kostspieliger Aufwand für Graphen mit möglicherweise weit mehr als hundert Knoten~\cite{gcn}.
Desweiteren führt ein Filter $\ve{\hat g} \in \gls{R}^N$ der Größe $N$ zu einem Lernaufwand in $\gls{O}\left(N\right)$, \dhe{} der Dimensionalität der Eingabedaten~\cite{Defferrard}.
Ebenso kann $\ve{\hat g}$ so nicht für das Lernen auf Graphen mit variierendem $N$ verwendet werden.
Um die oben genannten Schwächen zu umgehen kann $\hat g\left(\gls{lambda}_i\right)$ über ein Polynom\begin{equation}
  \hat g\left(\gls{lambda}_i\right) \approx \sum_{k=0}^K c_k\gls{lambda}_i^k
  \label{eq:spektraler_filter_approximation}
\end{equation}
vom Grad $K$ mit Koeffizienten ${\left[c_0, \ldots, c_K\right]}^{\top} \in \gls{R}^{K+1}$ approximiert werden~\cite{Hammond, Defferrard}.
Die Filtergröße sinkt somit auf einen konstanten Faktor $K$ mit Lernaufwand $\gls{O}\left(K\right)$, dem gleichen Aufwand klassischer zweidimensionaler \glspl{CNN}~\cite{Defferrard}.
$\ve{f}_{\mathrm{in}} \star \ve{\hat g}$ ergibt dann nach~\eqref{eq:matrix_potenz},~\eqref{eq:spektraler_faltungsoperator} und~\eqref{eq:spektraler_filter_approximation} approximiert durch~\cite{Defferrard}
\begin{equation}
  \ve{f}_{\mathrm{in}} \star \ve{\hat g} \approx \sum_{k=0}^K c_k\gls{Eiv}\gls{Lambda}^k\gls{Eiv}^{\top}\ve{f}_{\mathrm{in}} = \sum_{k=0}^K c_k \gls{Lboth}^k \ve{f}_{\mathrm{in}}.
  \label{eq:spektraler_faltungsoperator_approximation}
\end{equation}
Insbesondere ist die spektrale Faltung damit nicht mehr abhängig von der Berechnung der Eigenwerte \bzw{} Eigenvektoren von \gls{Lboth}.
Mittels Kapitel~\ref{laplace_eigenschaften} kann $\ve{f}_{\mathrm{in}} \star \ve{\hat g}$ in der Knotendomäne nun als eine \emph{lokaliserte lineare Transformation} interpretiert werden.
So sammelt ein Summand $\gls{Lboth}^k\ve{f}_{\mathrm{in}}$ des spektralen Filters an einem Knoten \gls{v} genau die Signale von Knoten auf, die maximal $k$ Kanten von \gls{v} entfernt liegen~\cite{Hammond}.
Eine Faltung über $f_{\mathrm{in}}\left(\gls{v}_i\right)$ wird damit als Linearkombination
\begin{equation*}
  f_{\mathrm{out}}\left(\gls{v}_i\right) \approx b_{ii} f_{\mathrm{in}}\left(\gls{v}_i\right) + \sum_{\gls{v}_j \in \gls{Neighbor}_K\left(\gls{v}_i\right)} b_{ij} f_{\mathrm{in}}\left(\gls{v}_j\right)
\end{equation*}
über dessen $k$-lokalisierte Nachbarschaft $\gls{Neighbor}_K\left(\gls{v}_i\right)$ mit $b_{ij} \coloneqq \sum_{k=0}^K c_k \gls{Lboth}^k_{ij}$ beschrieben~\cite{Shuman}.

\paragraph{Tschebyschow-Polynome}
\label{tschebyschow_polynome}

Obwohl der Aufwand zur Bestimmung von $\ve{f}_{\mathrm{in}} \star \ve{\hat g}$ durch die polynomielle Approximation und insbesondere durch den Wegfall der Berechnung der Eigenvektormatrix \gls{Eiv} deutlich reduziert wurde, ist diese immer noch recht teuer aufgrund der Berechnung der $K$-ten Potenz von $\gls{Lboth}$.
So ist \gls{Lboth} zwar eine dünnbesetzte Matrix mit $\left|\gls{E}\right| + N \ll N^2$, $N \leq \left|\gls{E}\right|$, Einträgen, $\gls{Lboth}^K$ ist dies jedoch zwangsläufig nicht.
Eine Lösung zu diesem Problem ist die Benutzung eines Polynoms mit einer rekursiven Formulierung.
Ein rekursives Polynom, dass dafür üblicherweise genutzt wird, ist das \emph{Tschebyschow-Polynom}, da sich dieses zusätzlich durch einen sehr günstigen Fehlerverlauf auszeichnet (\vgl{}~\cite{Hammond}).
Tschebyschow-Polynome bezeichnen eine Menge von Polynomen $\gls{T}_k\left(x\right) \colon \gls{R} \to \gls{R}$ mit dem rekursiven Zusammenhang
\begin{equation*}
  \gls{T}_k\left(x\right) = 2x\, \gls{T}_{k-1}\left(x\right) - \gls{T}_{k-2}\left(x\right)
\end{equation*}
mit $\gls{T}_0\left(x\right) = 1$ und $\gls{T}_1\left(x\right) = x$~\cite{Hammond}.
Ein Tschebyschow-Polynom $\gls{T}_k$ ist ein Polynom $k$-ten Grades und liegt im Intervall $\left[-1, 1\right]$ für $x \in \left[-1, 1\right]$~\cite{Hammond}.
Wir können diese Tatsache nutzen und anstatt $\gls{T}_k$ auf $\gls{Lambda} \in {\left[0, \gls{lambdamax}\right]}^{N \times N}$ auf die skalierten und verschobenen Eigenwerte $\gls{Lambdatilde} \coloneqq 2\gls{Lambda}/\gls{lambdamax} - \gls{I} \in {\left[-1, 1\right]}^{N \times N}$ anwenden~\cite{Defferrard}.
Die spektrale Faltung mittels Tschebyschow-Polynomen ergibt sich dann nach~\eqref{eq:spektraler_faltungsoperator_approximation} als
\begin{equation}
  \ve{f}_{\mathrm{in}} \star \ve{\hat g} \approx \sum_{k=0}^K c_k\gls{Eiv}\gls{T}_k\left(\gls{Lambdatilde}\right)\gls{Eiv}^{\top}\ve{f}_{\mathrm{in}},
  \label{eq:tschebyschow_faltung}
\end{equation}
wobei die Werte ${\left[c_0, \ldots, c_K\right]}^{\top} \in \gls{R}^{K+1}$ nun die Koeffizienten der Tschebyschow-Po\-ly\-no\-me $\gls{T}_k\left(\gls{Lambdatilde}\right) \in \gls{R}^{N \times N}$ bilden~\cite{Defferrard}.
$\gls{Eiv}\gls{T}_k\left(\gls{Lambdatilde}\right)\gls{Eiv}^{\top}$ kann aufgrund der polynomiellen Form von $\gls{T}_k$ und~\eqref{eq:matrix_potenz} ebenso auf $\gls{T}_k\left(\gls{Lbothtilde}\right)$ mit $\gls{Lbothtilde} \coloneqq \gls{Eiv}\gls{Lambdatilde}\gls{Eiv}^{\top} = \frac{2}{\gls{lambdamax}}\gls{Lboth} - \gls{I}$ angewendet werden~\cite{Defferrard}.
Damit kann~\eqref{eq:tschebyschow_faltung} weiter vereinfacht werden zu
\begin{equation}
  \ve{f}_{\mathrm{in}} \star \ve{\hat g} \approx \sum_{k=0}^K c_k\gls{T}_k\left(\gls{Lbothtilde}\right)\ve{f}_{\mathrm{in}}.
  \label{eq:tschebyschow_faltung_L}
\end{equation}
und ist nun ein rekursiv formulierter Faltungsoperator, der weiterhin ohne die explizite Berechnung von \gls{Eiv} auskommt~\cite{Defferrard}.
Für \gls{Lboth} kann $\gls{lambdamax} \leq 2$ auf dessen obere Schranke, \dhe{} $\gls{lambdamax} \coloneqq 2$, gesetzt werden sodass die Berechnung von \gls{lambdamax} vermieden werden kann ohne die Schranken von $\gls{Lambdatilde} \in {\left[-1, 1\right]}^{N \times N}$ zu verletzen.

Der rekursive Zusammenhang von $\gls{T}_k$ hilft uns dabei, $\ve{f}_{\mathrm{in}} \star \ve{\hat g}$ effizient zu bestimmen.
Berechne dafür $\ve{\bar f}_k \coloneqq \gls{T}_k\left(\gls{Lbothtilde}\right)\ve{f}_{\mathrm{in}} \in \gls{R}^N$ für alle $k \in \left\lbrace0, \ldots, K\right\rbrace$ rekursiv mit $\ve{\bar f}_0 = \ve{f}_{\mathrm{in}}$, $\ve{\bar f}_1 = \gls{Lbothtilde}\,\ve{f}_{\mathrm{in}}$ und $\ve{\bar f}_k = 2 \gls{Lbothtilde}\,\ve{\bar f}_{k-1} - \ve{\bar f}_{k - 2}$.
Dann ergibt sich $\ve{f}_{\mathrm{out}} = \left[\ve{\bar f}_0, \ve{\bar f}_1, \ldots, \ve{\bar f}_K\right]\ve{c} \in \gls{R}^N$ mit $\ve{c} \coloneqq {\left[c_0, c_1, \ldots, c_K\right]}^{\top} \in \gls{R}^{K+1}$ (\vgl{}~\cite{Hammond}).
$\ve{f}_{\mathrm{out}}$ lässt sich damit über $K + 1$ Multiplikationen einer dünnbesetzen Matrix mit einem Vektor und einer abschließenden Vektormultplikation beschreiben.
Mit $N \leq \left|\gls{E}\right|$ ergibt dies eine finale Laufzeit der spektralen Faltung von $\gls{O}\left(K\left|\gls{E}\right|\right)$~\cite{Defferrard}.

\paragraph{Implementierung}
\label{tschebyschow_tensor}

Für gewöhnlich besteht eine \gls{CNN}-Schicht nicht nur aus einem, sondern aus $M_{\mathrm{in}}$ vielen Signalen \bzw{} Merkmalen pro Knoten mit jeweils unterschiedlichen Filtern \bzw{} Gewichten pro Ein- und Ausgabekarte.
In klassichen zweidimensionalen \glspl{CNN} werden diese Merkmale auf $M_{\mathrm{out}}$ viele Merkmale abgebildet, in dem für jede Ausgabekarte über jede Eingabekarte gefaltet und dessen Ergebnisse sukzessive aufsummiert werden (\vgl{} Kapitel~\ref{convolutional_neural_networks}).
Modellieren wir diesen Fall für den spektralen Faltungsoperator, dann erhalten wir rekursiv für eine Merkmalsmatrix $\gls{F}_{\mathrm{in}} \in \gls{R}^{N \times M_{\mathrm{in}}}$ gefaltet auf eine Merkmalsmatrix $\gls{F}_{\mathrm{out}} \in \gls{R}^{N \times M_{\mathrm{out}}}$ über den $N$ Knoten eines Graphen \gls{G} mittels des Filtertensors $\gls{W} \in \gls{R}^{\left(K+1\right) \times M_{\mathrm{in}} \times M_{\mathrm{out}}}$
\begin{equation*}
  \gls{F}_{\mathrm{out}} \coloneqq \sum_{k=0}^K \ma{\bar F}_k,
\end{equation*}
wobei $\ma{\bar F}_k = \left(2\gls{Lbothtilde}\,\ma{\bar F}_{k -1} -  \ma{\bar F}_{k - 2}\right)\gls{W}_k \in \gls{R}^{N \times M_{\mathrm{out}}}$ mit $\ma{\bar F}_0 = \gls{F}_{\mathrm{in}}\gls{W}_0$ und $\ma{\bar F}_1 = \gls{Lbothtilde}\,\gls{F}_{\mathrm{in}}\gls{W}_1$.

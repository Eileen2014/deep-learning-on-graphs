\chapter{Ausblick}

\section{Attention Algorithmus}

If the graphs are of different sizes, you need to somehow represent them as fixed-size vectors before the fully connected layers (same principle as varying-length sentences being represented as fixed-size vectors by RNNs).
One way is to use an attention mechanism such as equation 7 in https://arxiv.org/abs/1511.05493.
% See: https://github.com/mdeff/cnn_graph/issues/5

Anderen Algorithmus vorstellen, der das ähnlich macht. SRR oder so.

Ausblick weiterhin erweiterhin auf 2,5d oder 3D Graphen.
Das sollte einfach möglich sein.

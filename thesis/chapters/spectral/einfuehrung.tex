\section{Einführung}

\begin{itemize}
  \item \emph{Spektrum} eines Graphen zur Untersuchung seiner Eigenschaften
  \item \emph{algebraische} oder \emph{spektrale Graphentheorie} genannt
\end{itemize}

Algebraische Methoden sind sehr effektiv bei Graphen, die regulär und symmetrisch sind.

\subsection{Eigenwerte, Eigenvektoren und Eigenfunktionen}

$\ma{M}\ve{v} = \lambda\ve{v}$\\
Zu einem Eigenwert $\lambda$ gibt es unendlich viele (skalierte) Eigenvektoren $\ve{v}$
Eigenvektor $\ve{v}$ ist dann eindeutig definiert mit $\left\|\ve{c}\right\|_2 = 1$
Wenn $\ma{M}$ symmetrisch ist und $\ve{v}_1$ und $\ve{v}_2$ zwei unterschiedliche Eigenvektoren, dann sind $\ve{v}_1 \gls{ortho} \ve{v}_2$
Jede symmetrische Matrix hat $n$ Eigenwerte mit $\lambda_0 \leq \cdots \lambda_{n-1}$


\subsection{Der Laplacian und seine Eigenwerte}

Der Graph Laplacian ist eine Generalisierung des Laplacian auf einem Gitter.

Der Laplacian \gls{L} eines Graphen \gls{G} ist definiert als $\gls{L} = \gls{D} - \gls{A}$~\cite{Chung}.
Der normalisierte Laplacian \gls{Lnorm} ist definiert als $\gls{Lnorm} = \gls{D}^{-\frac{1}{2}} \gls{L} \gls{D}^{-\frac{1}{2}}$~\cite{Chung}.
Es gilt die Konvention, dass ${\left(\gls{D}^{-\frac{1}{2}}\right)}_{ii} = 0$ falls $\gls{D}_{ii} = 0$
Für verbundene Graphen gilt weiterhin $\gls{Lnorm} = \gls{I} - \gls{D}^{-\frac{1}{2}} \gls{A} \gls{D}^{-\frac{1}{2}}$~\cite{Chung}.
Wenn \gls{G} $k$-regulär ist, dann gilt $\gls{Lnorm} = \gls{I} - \frac{1}{k} \gls{A}$.~\cite{Chung}\todo{das gilt natürlich nur im ungewichteten Fall, also weg?}
\todo{was gilt denn alles im gewichteten?}

\gls{L} und \gls{Lnorm} sind keine ähnlichen Matrizen.
Insbesondere sind ihre Eigenvektoren unterschiedlich.
Die Nutzung des \gls{L} oder \gls{Lnorm} ist damit abhängig von dem Problem, welches man betrachtet.~\cite{Hammond}.

Wir schreiben \gls{Lboth} wenn die Wahl des Laplacian (unnormalisiert, normalisiert) irrelevant ist.

Jede Reihen- und Spaltensumme von $\gls{Lboth}$ ist $0$, d.h.\ $\sum_i \gls{Lboth}_{ij} = 0$ und $\sum_i \gls{Lboth}_{ji} = 0$ für alle $i \in \left\{1, \ldots, n\right\}$.
\todo{stimmt das für \gls{Lnorm}?}
$\gls{Lboth} \in \gls{R}^{n \times n}$ hat genau $n$ Eigenwerte ${\left\{\lambda_i\right\}}_{i = 0}^{n-1}$.
\gls{Lboth} ist eine symmetrische reelle Matrix, d.h.\ insbesondere liegen ihre Eigenwerte $\lambda_i$ in $\gls{R+}$.\\
\todo{positive semidefinitheit}
\todo{Lambda Ordering}
Anzahl der Eigenvektoren gleich Null ist die Anzahl an Komponenten, die ein Graph besitzt.
$0 = \lambda_0 < \lambda_1 \leq \lambda_2 \leq \cdots \leq \lambda_{n-1}$ wenn Graph verbunden.\todo{quelle}\\
$\lambda_0 = 0$, da $\ve{u}_0 = {\left[1, \ldots, 1\right]}^{\top}$ Eigenvektor von \gls{Lboth}\todo{quelle}\\
$\gls{Lambda} = \gls{diag}\left(\left[\lambda_0, \ldots, \lambda_{n-1}\right]\right)$\\
Für einen Graphen \gls{G} definieren wir $\lambda_{\gls{G}} := \lambda_1$ und $\lambda_{\max} := \lambda_{n-1}$
\todo{lambda upper bound}
\todo{$\gls{L}^k$}

Für \gls{Lnorm} gilt $\lambda_{\max} \leq 2$\todo{quelle}

Eine Verschrumpfung eines Graphen \gls{G} kann beschrieben werden über zwei verschiedene Knoten $u$ und $v$ zu einem neuen Knoten $v^*$ mit
\begin{align}
  \gls{w}\left(x,v^*\right) &= \gls{w}\left(x, u\right) + \gls{w}\left(x, v\right)\\
  \gls{w}\left(v^*, v^*\right) &= \gls{w}\left(u, u\right) + \gls{w}\left(v, v\right) + 2\gls{w}\left(u,v\right)
\end{align}

Für einen Graphen \gls{G}, gilt für einen Graphen $H$ der aus \gls{G} verkleinert wurde

\begin{equation}
  \lambda_{\gls{G}} \leq \lambda_H
\end{equation}

\section{Spectral Graph Domain}

\begin{itemize}
  \item \emph{Spectral Graph Domain}: Der Raum der Eigenfunktionen von $\mathcal{L}$
  \item Analogon (Nachbildung) einer \emph{Fourier-Transformation} von Funktionen auf gewichteten Graphen
\end{itemize}

Eine beliebige Funktion $f: V \rightarrow \mathbb{R}$ kann als ein Vektor in $\mathbb{R}^n$ gesehen werden.
Dies impliziert eine Ordnung auf den Knoten.
Wir schreiben $f \in \mathbb{R}^n$ für Funktionen auf den Knoten eines Graphen und $f(m)$ für den Wert des $m$ten Knoten.

Dann gilt für eine beliebige Funktion $f \in \mathbb{R}^n$

\begin{equation}
  \mathcal{L}f(x) = \sum_{x~y} w(x, y) \cdot (f(x) - f(y))
\end{equation}

wobei die Summe über $x~y$ die Summierung über alle Knoten $y$ beschreibt, die adjazent zu $x$ sind.

Angenommen $G$ ist als ein reguläres Gitter definiert der Breite und Höhe $M$
Dann hat ein Knoten $v_{x,y}$ genau 4 Nachbarn mit Kantengewicht $\frac{1}{{(\delta w)}^2}$, bei dem $\delta w$ die euklidsche Distanz zwischen zwei Gitterpunkten beschreibt.

Für eine Funktion $f: M \times M \rightarrow \mathbb{R}$ gilt dann:

\begin{equation}
  \mathcal{L}f(x, y) = \frac{4f(x,y) - f(x+1, y) - f(x-1, y) - f(x, y+1) - f(x, y-1)}{{(\delta w)}^2}
\end{equation}

Damit kann ein Signal $f$ mit der Multiplikation mit $\mathcal{L}$ als eine Weiterpropagation von $f$ unter der Berücksichtigung der lokalen Nachbarn verstanden werden (\emph{5-point Stencil}, d.h.\ $\mathcal{L}f \approx - \nabla^2 f$).

\section{Diskrete Fourier Transformation}

$\mathcal{L}$ besitzt genau $n$ orthogonal zueinander stehende Eigenvektoren $\lbrace u_l \rbrace_{l=1}^n \in \mathbb{R}^n$.
Eigenvektoren $u_i$ sind auf $1$ normiert, d.h.\ $||u_i||_2 = 1$.
Diese werden auch \emph{Graph Fourier Modes} genannt.
Diesen sind Eigenwete $\lbrace \lambda_l \rbrace_{l=1}^n \in \mathbb{R}$ zugeordnet, die die \glqq{}Frequenzen\grqq\ bzw.\ das Spektrum des Graphen beschreiben oder visuell betrachtet die Ausdehnung des Raumes, den die Eigenvektoren aufspannen.
Bemerke dass $\lambda_0 = 0$, da für den Eigenvektor $\vec{u_0} = {(1, 1, \ldots, 1)}^T$ gilt, dass $\mathcal{L}\vec{u_0} = 0$.
$\mathcal{L}$ ist diagonalisierbar über $\mathcal{L} = U \Lambda U^T$, wobei $U = [u_1, \ldots, u_n] \in \mathbb{R}^{n \times n}$ die \emph{Fourier Basis} und $\Lambda = \text{diag}([\lambda_0, \ldots, \lambda_n]) \in \mathbb{R}^{n \times n}$.
Die \emph{Fourier Transformation} eines Signals $x \in \mathbb{R}^n$ ist dann definiert als $\hat{x} = U^{T}x$ und die Inverse als $x = U\hat{x}$.

\section{Faltung}

Wir suchen einen Operator $x *_G g$, der eine Faltung zweier Eingangssignale $x, g$ zu einem Ausgangssignal umleitet.
$x$ beschreibt dabei die Knotenattribute und $g$ die Gewichte.

\subsection{Faltung in CNNs}

In der Funktionalanalysis beschreibt die \emph{Faltung} einen mathematischen Operator, der für zwei Funktion $f$ und $g$ eine dirtte Funktion $f * g$ liefert.
Die Faltung kann als ein Produkt von Funktionen vertanden werden.

Anschaulich ist $(f * g)(x)$ der \emph{gewichtete Mittelwert} von $f$, wobei die Gewichtung durch $g$ gegeben ist.

Angenommen wir wollen über einer Matrix mit einem \emph{Filter} falten.
Sei unsere Eingangsmatrix $3 \times 4$ und unsere Filtergröße $2 \times 2$.

Dann gilt zum Beispiel für den Faltungsoperator $*$ in einem Convolutional Neural Network:

\begin{equation}
  \begin{pmatrix}
    1 & 2 & 3 & 1\\
    4 & 5 & 6 & 1\\
    7 & 8 & 9 & 1
  \end{pmatrix} * \begin{pmatrix}
    1 & 1\\
    1 & 1
  \end{pmatrix} = \begin{pmatrix}
    12 & 16 & 11\\
    24 & 28 & 17
  \end{pmatrix}
\end{equation}

$f: 3 \times 4 \rightarrow \mathbb{R}$ und $g: 2 \ times 2 \rightarrow \mathbb{R}$, dann ist $*$ definiert als

\begin{equation}
  (f * g)(x, y) = \sum_{x_i \in [x, x+1]\\y_i \in [y, y+1]} f(x_i, y_i)g(x-x_i, y-y_i)
\end{equation}

\subsection{Faltung auf Graphen}

Da wir keinen Translationsoperator auf der Domäne der Knoten $x$ beschreiben können, müssen wir unseren Faltungsoperator in der Fourier-Domäne beschreiben.
Dafür wandeln wir unsere Knotenmenge $x$ zuerst in $\hat x$ um.

Wir definieren $*_G$ in der Fouier-Domäne als

\begin{equation}
  x *_G g = U \cdot (U^T \cdot x \odot \hat g)
\end{equation}

wobei $\odot(A, B) = (a_{ij} \cdot b_{ij})$ die elementweise Multiplikation bzw.\ das \emph{Hadamard-Produkt}.

Das Hadamard-Produkt löst sich auf, wenn $\hat g$ als eine Diagonalmatrix repräsentiert wird. Dann gilt

\begin{equation}
  x *_G g = U \begin{pmatrix}
    \hat g(\lambda_0) & \cdots & 0\\
    0 & \cdots & \hat g(\lambda_n)
  \end{pmatrix}U^T x = U \hat g(\Lambda) U^T x
\end{equation}

Dann beschreibt $\hat g(\Lambda) = \text{diag}(\theta)$ eine Gewichtsfunktion mit $n$ Variablen, $\theta \in \mathbb{R}^n$.
Damit ist die Faltung bzw.\ die Gewichtung abhängig von der Input-Größe $n$, was extrem schlecht ist.

\subsection{Offene Fragen}

\begin{itemize}
  \item Wie erklärt sich noch einmal der normalisierte Laplacian?
  \item Warum wird $\hat g$ als Diagonalmatrix repräsentiert?
  \item Wie kommt die Convolution zustande mit dem $*$ Operator?
  \item Was passiert bei gerichteten Graphen???? Wir haben keinen symmetrischen und insbesondere keinen positiv definiten
\end{itemize}

\section{Chebyshev Polynome}

\section{Probleme}

Rotationsinvariant

\section{Pfadlänge}

wenn $d_G(m,n) > k$, dann ${(L^k)}_{m, n} = 0$
(normalisiert sowie unnormalisiert (siehe Wavelet Lemma 5.4))
